{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e1b6a9",
   "metadata": {},
   "source": [
    "## Deep Learning Playground\n",
    "#### A Cuda-Enabled environment\n",
    "##### J-A-Collins\n",
    "\n",
    "\n",
    "##### Install the appropriate CUDA-enabled PyTorch version here: https://pytorch.org/get-started/locally/\n",
    "##### For Windows 10/pip/CUDA 11.6: \n",
    "pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d10a5791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage:\n",
      "+------------+---------+\n",
      "| Memory     | Usage   |\n",
      "+============+=========+\n",
      "| Allocated: | 0.0 GB  |\n",
      "+------------+---------+\n",
      "| Cached:    | 0.0 GB  |\n",
      "+------------+---------+\n",
      "\n",
      "\n",
      "+-----------------+----------------------------------------------+\n",
      "| Stat            | Value                                        |\n",
      "+=================+==============================================+\n",
      "| CUDA enabled:   | True                                         |\n",
      "+-----------------+----------------------------------------------+\n",
      "| Device count:   | 1                                            |\n",
      "+-----------------+----------------------------------------------+\n",
      "| Current device: | 0                                            |\n",
      "+-----------------+----------------------------------------------+\n",
      "| GPU:            | NVIDIA GeForce GTX 1650 Ti with Max-Q Design |\n",
      "+-----------------+----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Test Cuda enabled, get GPU metrics\n",
    "import torch\n",
    "from tabulate import tabulate\n",
    "\n",
    "table = [[\"CUDA enabled:\", torch.cuda.is_available()],\n",
    "         [\"Device count:\", torch.cuda.device_count()],\n",
    "         [\"Current device:\", torch.cuda.current_device()],\n",
    "         [\"GPU:\", torch.cuda.get_device_name(0)]]\n",
    "\n",
    "# Device 0 refers to the GPU\n",
    "# Setting device to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Additional:\n",
    "if device.type == 'cuda':\n",
    "    memory_usage = [[\"Allocated:\", '{} GB'.format(round(torch.cuda.memory_allocated(0)/1024**3,1))],\n",
    "                    [\"Cached:\", '{} GB'.format(round(torch.cuda.memory_reserved(0)/1024**3,1))]]\n",
    "    print('Memory Usage:')\n",
    "    print(tabulate(memory_usage, headers=[\"Memory\", \"Usage\"], tablefmt='grid'))\n",
    "print(\"\\n\")\n",
    "print(tabulate(table, headers=[\"Stat\", \"Value\"], tablefmt='grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudavenv",
   "language": "python",
   "name": "cudavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
